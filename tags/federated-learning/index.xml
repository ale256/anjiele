<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>federated learning on Anjie Le 勒安捷</title>
    <link>https://ale256.github.io/tags/federated-learning/</link>
    <description>Recent content in federated learning on Anjie Le 勒安捷</description>
    <generator>Source Themes academia (https://sourcethemes.com/academic/)</generator>
    <language>en</language>
    <lastBuildDate>Thu, 09 Feb 2023 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://ale256.github.io/tags/federated-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Errors in the proof of convergence of SCAFFOLD</title>
      <link>https://ale256.github.io/post/scaffold/</link>
      <pubDate>Thu, 09 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>https://ale256.github.io/post/scaffold/</guid>
      <description>&lt;h2 id=&#34;in-lemma-9&#34;&gt;In Lemma 9&lt;/h2&gt;
&lt;p&gt;$$(1-2\mu\eta_r)^{(K-1)/2}=(1-\frac{2\gamma_r}{R(K-1)})^{(K-1)/2}\leq 1-\gamma_r/R$$
only holds for $K\leq 3$. Otherwise, LHS $\geq$ RHS rather than $\leq$.&lt;/p&gt;
&lt;h2 id=&#34;in-lemma-14&#34;&gt;In Lemma 14&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;For $\tau_3$, haven&amp;rsquo;t found a clear reason to support why it is $c-c_i+\nabla f_i(x)$ rather than $c-c_i-\nabla f_i(x)$.
If this is a typo, then the proof for $\tau_3$ doesn&amp;rsquo;t work.&lt;/li&gt;
&lt;li&gt;In the line of equation below (25), have an extra $\beta$ in the term $7\beta\eta_l^2\sigma^2$, so that in the final result, the coefficient of $\sigma^2$ is missing by a factor of $63\tilde{\eta}^2$.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
